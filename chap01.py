"""
Script for exercises from Chapter 1 of Theoretical Neuroscience book
"""

import numpy as np
import matplotlib.pyplot as plt
import neuro_tools as nt
from scipy import signal


def exercise1(duration = 10,  # seconds
              firing_rate = 100,  # Hz
              fano_countings = np.arange(1, 101)/1000,  # seconds
              hist_bins = 50, # number
              ):
    # Generating spikes
    spike_times = nt.poisson_spike_generator(duration, firing_rate)
    spikes = nt.SpikeTrain(duration, spike_times)
    # Coefficient of variation
    print("Coefficient of variation: {}".format(spikes.coefficient_of_variation()))
    # Fano factor:
    if type(fano_countings) in [int, float] or len(fano_countings) < 10:
        print("Fano Factors: {}".format(spikes.fano_factor(fano_countings)))
    else:
        plt.plot(fano_countings*1000, spikes.fano_factor(fano_countings))
        plt.plot(fano_countings[[0,-1]]*1000, np.ones(2))
        plt.title("Fano Factors")
        plt.xlabel("Counting interval [ms]")
        plt.show()
    # Interspike interval histogram
    spikes.plot_interspike_interval_histogram(hist_bins)
    plt.show()


def exercise2(duration = 10,  # seconds
              firing_rate = 100,  # Hz
              fano_countings = np.arange(1, 101)/1000,  # seconds
              hist_bins = 50,  # number
              taus = np.arange(1, 21)/1000,  # seconds
              tau_fano = 0.01, # seconds
              ):
    """
    Exercise 2:

    Add a refractory period to the Poisson spike generator by allowing
    the firing rate to depend on time. Initially, set the firing rate to a
    constant value, r(t) = r_0 . After every spike, set r(t) to 0, and then
    allow it to recover exponentially back to r_0 with a time constant τ_ref
    that controls the refractory recovery rate. In other words, have r(t)
    obey the equation

    τ_ref * (dr/dt) = r_0 − r

    except immediately after a spike, when it is set to 0. Plot the coeffi-
    cient of variation as a function of τ_ref over the range 1 ms ≤ τ_ref ≤ 20
    ms, and plot interspike interval histograms for a few different values
    of τ_ref in this range. Compute the Fano factor for spike counts ob-
    tained over counting intervals ranging from 1 to 100 ms for the case
    τ_ref = 10 ms.
    """


    # Plot of the coefficient of variation as a function of τ
    # Computing coefficient of variations
    coef_of_vars = []
    for tau in taus:
        ref_rate = lambda time, last_time: nt.recovering_firing_rate(
                            firing_rate, time, last_spike=last_time, tau=tau)
        spikes = nt.poisson_spike_generator(duration, firing_rate,
                                            rate=ref_rate)
        spikes = nt.SpikeTrain(duration, spikes)
        coef_of_vars.append(spikes.coefficient_of_variation())
    # Plotting
    plt.plot(taus*1000, coef_of_vars)
    plt.xlabel("tau (ms)")
    plt.title("Coefficients of variation")
    plt.show()

    # Plot of interspike interval histograms
    # Picking 4 random taus
    np.random.shuffle(taus)
    rand_taus = np.sort(taus[:4])

    for tau in rand_taus:
        ref_rate = lambda time, last_time: nt.recovering_firing_rate(
                            firing_rate, time, last_spike=last_time, tau=tau)
        spikes = nt.poisson_spike_generator(duration, firing_rate,
                                            rate=ref_rate)
        spikes = nt.SpikeTrain(duration, spikes)
        title = "Interspike interval histogram (tau = {} ms)".format(tau*1000)
        spikes.plot_interspike_interval_histogram(hist_bins, title=title)
        plt.show()

    # Fano factor for τ = 10 ms (tau_fano)
    ref_rate = lambda time, last_time: nt.recovering_firing_rate(
                        firing_rate, time, last_spike=last_time, tau=tau_fano)
    spikes = nt.poisson_spike_generator(duration, firing_rate, rate=ref_rate)
    spikes = nt.SpikeTrain(duration, spikes)
    print("Fano Factor: {}".format(spikes.fano_factor(fano_countings)))


def exercise3(duration = 10,  # seconds
              firing_rate = 100,  # Hz
              tau = 0.01,  # seconds
              max_time = 0.1,  # seconds
              time_step = 0.001,  # seconds
              ):
    """ 
    Exercise 3

    Compute autocorrelation histograms of spike trains generated by a
    Poisson generator with a constant firing rate of 100 Hz, a constant
    firing rate of 100 Hz together with a refractory period modeled as
    in exercise 2 with τ ref = 10 ms, and a variable firing rate r(t) =
    100(1 + cos(2πt/25 ms)) Hz. Plot the histograms over a range from 0
    to 100 ms.
    """
    # Firing rates
    const_rate = None  # None is interpreted as constant firing rate
    # const_rate = lambda time, last_time: firing_rate
    ref_rate = lambda time, last_time: nt.recovering_firing_rate(
                            firing_rate, time, last_spike=last_time, tau=tau)
    cos_rate = lambda time, last_time: 100*(1+np.cos(2*np.pi*time/0.025))
    
    # list of tuples (firing rate, upper bound)
    rates = [(const_rate, firing_rate, "const firing rate"),
             (ref_rate, firing_rate, "reviving firing rate"),
             (cos_rate, 200, "cosine firing rate")]

    for rate, rate_bound, rate_name in rates:
        spikes = nt.poisson_spike_generator(duration, rate_bound, rate=rate)
        spikes = nt.SpikeTrain(duration, spikes)
        spikes.plot_autocorrelation_histogram(time_step, max_time, 
                title=f"Autocorrelation histogram for {rate_name}")
        plt.show()


def exercise4(duration = 10,  # seconds
              time_step = 0.001,  # seconds
              firing_rate = 100,  # Hz
              init_rate = 0,  # Hz
              tau_approx = 0.028,  # seconds
              tau_min = 0.001,  # seconds
              tau_max = 0.1,  # seconds
              tau_step = 0.001,  # seconds
              start_spike = 500,  # number of starting spike
              spikes_num = 100,  # number of spikes in the plots
              ):
    """ 
    Exercise 4:

    Generate a Poisson spike train with a time-dependent firing rate
    r(t) = 100*(1 + cos(2πt/300 ms)) Hz. Approximate the firing rate from
    this spike train using a variable r_approx that satisfies

    τ_approx * (dr_approx/dt) = −r_approx,

    except that r_approx → r_approx + 1/τ_approx every time a spike occurs.
    Make plots of the true rate, the spike sequence generated, and the
    estimated rate. Experiment with a few different values of τ_approx
    in the range of 1 to 100 ms. Determine the best value of τ_approx
    by computing the average squared error of the estimate, int dt(r(t) −
    r_approx(t))^2 , for different values of τ_approx , and finding the value of
    τ_approx that minimizes this error.
    """
    # Cosine firing rate
    cos_rate = lambda time, last_time: firing_rate*(1+np.cos(2*np.pi*time/0.3))
    rate_max = 200
    # Generate spikes
    spikes = nt.poisson_spike_generator(duration, rate_max, rate=cos_rate)
    spikes = nt.SpikeTrain(duration, spikes)

    # Finding the best tau
    times = np.linspace(0, duration, int(duration/time_step)+1)
    cos_rates = cos_rate(times, None)
    errs = []
    for tau in np.arange(tau_min, tau_max+tau_step, tau_step):
        approx_rates = nt.approximate_rate(times, spikes.spikes, tau, init_rate)
        # Using Crank-Nicholson approximation of the integral
        err = (cos_rates-approx_rates)**2
        err[[0,-1]] = 1/2*err[[0,-1]]
        errs.append((err.sum(), tau))

    # Plot the taus
    # NOTE: There is also dependence on initial firing rate, but that is
    # negligible as the initial firing rate dacays very quickly and for
    # longer experiments it has no effect
    errs, taus = zip(*sorted(errs))
    print(f"Best τ_approx is {taus[0]*1000} s")
    taus = np.array(taus)*1000
    plt.plot(taus[:-10], errs[:-10], "x")
    plt.title("Dependence of error on τ_approx")
    plt.ylabel("Average squared error")
    plt.xlabel("τ_approx (ms)")
    plt.show()

    # Plot rates and spikes
    start_time = spikes.spikes[start_spike]
    end_time = spikes.spikes[start_spike + spikes_num-1]
    times = np.linspace(start_time, end_time, 250)
    plt.vlines(spikes.spikes[start_spike: start_spike + spikes_num], 
                firing_rate/2, firing_rate*3/2)
    plt.plot(times, cos_rate(times, None))
    plt.plot(times, nt.approximate_rate(times, spikes.spikes, tau_approx,
             init_rate))
    plt.show()


def exercise6(duration = 10,  # seconds
              time_step = 0.001,  # seconds
              sigma = 1,  # variability of white noise
              cyclic_stimulus = True,  # cyclicity of stimulus
             ):
    """
    Exercise 6:

    Build an approximate white-noise stimulus by choosing random val-
    ues at discrete times separated by a time-step interval ∆t. Plot its
    autocorrelation function and power spectrum (use the MATLAB® func-
    tion spectrum or psd). Discuss how well this stimulus matches an
    ideal white-noise stimulus given the value of ∆t you used.
    """
    # Gaussian white noise stimulus generation
    # Based on the book page 23
    bins = int(duration/time_step)
    s = sigma/(time_step**0.5)
    rng = np.random.default_rng()
    wns = s*rng.standard_normal(bins)

    # Autocorrelation
    # very inefficient code, done mostly for the fun of 
    # cc = (wns*wns[np.arange(bins)-np.arange(bins)[:,np.newaxis]]).sum(axis=1)/bins
    if cyclic_stimulus:
        wns_cyclic = np.concatenate((wns, wns))  # Double the array
        autocorr = np.correlate(wns_cyclic,wns)[:-1]
        autocorr = autocorr/bins
    else:
        autocorr = np.correlate(wns,wns, mode='full')
        autocorr = autocorr[autocorr.argmax():]/bins

    plt.plot(autocorr)
    plt.title("Autocorrelation of the generated white noise")
    plt.xlabel("time shift [seconds]")
    plt.show()
    # NOTE: for analysis of noise signal direct FFT is biased and noisy
    # leads towards periodogram. Therefore Welch's analysis is used instead
    freqs, psd = signal.welch(wns, 1/time_step)
    plt.plot(freqs, psd)
    plt.title("Estimated power spectrum (Welch's method)")
    plt.xlabel("Frequency [Hz]")
    plt.show()


def exercise7(tau = 0.02,  # seconds
              duration = 10,  # seconds
              time_step = 0.001,  # seconds
              max_time = 0.15,  # seconds
              trials = 1000, # number of trials
              r0 = 20,  # Hz
              sigma = 1,  # variability of white noise
              adjust_signal = True,
             ):
    """
    Exercise 7:

    Consider a model with a firing rate determined in terms of a stimulus
    s(t) by integrating the equation

    τ_r * (dr_est(t)/dt) = [r_0 + s]_+ − r_est(t),

    where r_0 is a constant that determines the background firing rate and
    τ_r = 20 ms. Drive the model with an approximate white-noise stim-
    ulus. Adjust the amplitude of the white-noise and the parameter r_0
    so that rectification is not a big effect (i.e. r_0 + s > 0 most of the time).
    From the responses of the model, compute the stimulus-response cor-
    relation function, Q_rs . Next, generate spikes from this model using a
    Poisson generator with a rate r_est(t), and compute the spike-triggered
    average stimulus from the spike trains produced by the white-noise
    stimulus. By comparing the stimulus-response correlation function
    with the spike-triggered average, verify that equation 1.22 is satis-
    fied. Examine what happens if you set r_0 = 0, so that the white-noise
    stimulus becomes half-wave rectified.
    """

    # NOTE: adjust_signal:
    # if True, sigma will be adjusted so that s+r0 > 0 most of the time
    # NOTE: max_time:
    # time limit for evaluation of spike triggered average

    # Adjusting noise properties so that rectification is not a big effect
    if adjust_signal and np.sqrt(time_step)*r0 < 3*sigma:
        # Gaussian white noise, r0>= 3*std means r0>s most of the time
        noise_std = r0/3
        sigma = np.sqrt(time_step)*r0/3
    else:
        noise_std = sigma/np.sqrt(time_step)

    # Generate noise
    rng = np.random.default_rng()
    bins = int(duration/time_step)
    wnstim = noise_std*rng.standard_normal(bins)

    # Firing rate, using Euler explicit method solution:
    rate = np.empty(bins)
    rate[0] = r0  # initial value, r0 is the solution for no stimulus
    for i in range(1, bins):
        rate[i] = rate[i-1] + time_step/tau*(max(r0+wnstim[i-1], 0)-rate[i-1])

    # stimulus- response correlation
    rs_corr = np.correlate(np.concatenate((wnstim, wnstim)), rate)[::-1]/bins
    plt.plot(rs_corr)
    plt.title("Stimulus-response correlation")
    plt.show()

    # Generates spikes using r_est(), Poisson process
    response = np.zeros(bins)
    for i in range(trials):
        response += nt.poisson_response_generator(rate, time_step)
    response = response/trials

    # Spike triggered average
    n = response.sum()
    time_bins = int(max_time/time_step)
    sta = np.correlate(np.concatenate((wnstim[-time_bins:], wnstim)),
                       response)/n

    # Verify equation 1.22
    # C(tau) = 1/<r> * Q_rs(-tau), where C is spike-triggered average
    plt.plot(sta, label="Spike triggered average")
    plt.plot(rs_corr[:time_bins+1][::-1]/rate.mean(),
             label="Rate-stim correlation")
    plt.legend()
    plt.show()


def exercise8(duration = 20*60,  # seconds
              sampling = 500,  # Hz
              time_step = 0.002,  # seconds
              max_time = 0.3,  # seconds
             ):
    """
    Exercise 8:

    MATLAB® file c1p8.mat contains data collected and provided by Rob
    de Ruyter van Steveninck from a fly H1 neuron responding to an ap-
    proximate white-noise visual motion stimulus. Data were collected
    for 20 minutes at a sampling rate of 500 Hz. In the file, rho is a vector
    that gives the sequence of spiking events or nonevents at the sampled
    times (every 2 ms). When an element of rho is one, this indicates the
    presence of a spike at the corresponding time, whereas a zero value
    indicates no spike. The variable stim gives the sequence of stimulus
    values at the sampled times. Calculate and plot the spike-triggered
    average from these data over the range from 0 to 300 ms (150 time
    steps). (Based on a problem from Sebastian Seung.)
    """

    # Loading data
    response, stimulus = nt.load_c1p8()

    # Computing spike triggered average
    n = response.sum()
    time_bins = int(max_time/time_step)
    # This is faster numpy way - create array where each row represents values
    # of the stimuli in range from -300 to 0 ms relative to spikes
    # one row represents one spike in data 
    # after that making sum in columns and dividing by spike count
    sta = stimulus[np.arange(-time_bins, 1)
                    + response.nonzero()[0][:, np.newaxis]].sum(axis=0)/n
    # NOTE: this works only because rho values are in [0, 1] 
    # for <rho> true correlation computing is necessary:
    # sta = np.correlate(np.concatenate(stimulus[-time_bins-1:],
    #                                   stimulus), response)/n

    # Plot of spike triggered average
    plt.plot(np.arange(-max_time, time_step, time_step)*1000, sta)
    plt.title("Spike triggered average")
    plt.ylabel("Relative stimulus")
    plt.xlabel("time before spike (ms)")
    plt.show()


def exercise9(max_time = 0.3,  # seconds
              time_step = 0.002,  # seconds
              max_separation = 0.1,  # seconds
             ):
    """
    Exercise 9:

    Using the data of problem 8, calculate and plot stimulus averages
    triggered on events consisting of a pair of spikes (which need not nec-
    essarily be adjacent) separated by a given interval (as in figure 1.10).
    Plot these two-spike-triggered average stimuli for various separation
    intervals ranging from 2 to 100 ms. (Hint: in MATLAB® , use convo-
    lution for pattern matching: e.g. find(conv(rho,[1 0 1])==2) will
    contain the indices of all the events with two spikes separated by 4
    ms.) Plot, as a function of the separation between the two spikes,
    the magnitude of the difference between the two-spike-triggered av-
    erage and the sum of two single-spike-triggered averages (obtained3
    in exercise 8) separated by the same time interval. At what temporal
    separation does this difference become negligibly small. (Based on a
    problem from Sebastian Seung.)
    """

    # Loading data
    response, stimulus = nt.load_c1p8()

    for separation in range(1, int(max_separation/time_step)+1):
        pattern = np.zeros(separation+1)
        pattern[[0,-1]] = 1
        # indices of wanted responses
        indices = (np.convolve(response, pattern, 
                                mode='valid') == 2).nonzero()[0]
        n = indices.size
        # Computing spike triggered average
        sta = stimulus[np.arange(-int(max_time/time_step), 1, 1)
                        + indices[:, np.newaxis]].sum(axis=0)/n
        # Plot of spike triggered average
        plt.plot(np.arange(-max_time, time_step, time_step)*1000, sta)
        plt.title("Multi-spike triggered average, spike separation = " 
                                        + f"{separation*time_step*1000} ms")
        plt.ylabel("Relative stimulus")
        plt.xlabel("time before spike (ms)")
        plt.show()

    # The most interesting spike sequences are:
    # [1, 1] - spike triggered average has a significant drop in stimulus
    # before the big raise of stimulus, also the peak is much higher than in
    # the case of independent neurons
    # [1, 0, 1] - spike triggered average react on much higher peak than 
    # independent neurons
    # for larger separation there appears to be two peaks in stimulus,
    # that's because both neurons fire independently and each has its own peak


def exercise10(max_time = 0.3,  # seconds
              time_step = 0.002,  # seconds
              max_separation = 0.1,  # seconds
             ):
    """
    Exercise 10:

    Using the data of problem 8, find the spike-triggered average stimu-
    lus for events that contain exactly two adjacent spikes separated by
    various different intervals ranging from 2 to 100 ms (e.g. for 4 ms,
    the event [1 0 1] but not the event [1 1 1]). This is distinct from
    exercise 9 in which we only required two spikes separated by a given
    interval, but did not restrict what happened between the two spikes.
    Compare results of the exclusive case considered here with those of
    the inclusive two-spike-triggered average computed in exercise 9. In
    what ways and why are they different? (Based on a problem from
    Sebastian Seung.)
    """

    # Loading data
    response, stimulus = nt.load_c1p8()

    for separation in range(1, int(max_separation/time_step)+1):
        # indices of spikes separated be a given time
        pattern = np.zeros(separation+1)
        pattern[[0,-1]] = 1
        indices1 = (np.convolve(response, pattern, 
                                mode='valid') == 2).nonzero()[0]
        # indices of all pairs of spikes which are in a given time interval
        indices2 = (np.convolve(response, np.ones(separation+1),
                                mode='valid') == 2).nonzero()[0]
        # indices of wanted responses
        indices = np.intersect1d(indices1, indices2, assume_unique=True)
        n = indices.size
        # Computing spike triggered average
        sta = stimulus[np.arange(-int(max_time/time_step), 1, 1)
                        + indices[:, np.newaxis]].sum(axis=0)/n
        # Plot of spike triggered average
        plt.plot(np.arange(-max_time, time_step, time_step)*1000, sta)
        plt.title("Multi-spike triggered average, spike separation = " 
                                        + f"{separation*time_step*1000} ms")
        plt.ylabel("Relative stimulus")
        plt.xlabel("time before spike (ms)")
        plt.show()

